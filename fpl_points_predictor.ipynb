{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efb9b53-ab5e-4cec-b9fa-f2e6f216bf05",
   "metadata": {},
   "source": [
    "### Importing Necessary Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a657b",
   "metadata": {},
   "source": [
    "`pandas` and `numpy` for dataframe processing.\n",
    "\n",
    "`sklearn` as a source of regressor models\n",
    "\n",
    "`pulp` linear problem solvers for team composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "826f8c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pulp import LpMaximize, LpProblem, LpVariable, lpSum, LpInteger, LpStatus, LpBinary, LpConstraintVar, LpConstraint, LpAffineExpression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224b450-bbfa-42c2-a0c0-56c8718de675",
   "metadata": {},
   "source": [
    "### Importing the Data\n",
    "\n",
    "FPL has API which can be used to query current and historical data. Luckily, its also being aggregated into a single CSV at https://github.com/vaastav/Fantasy-Premier-League (imported as git submodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a2aacdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2734803/3321494464.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/data/cleaned_merged_seasons.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/data/cleaned_merged_seasons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove string data from the dataset\n",
    "del df[\"season_x\"]\n",
    "del df[\"opp_team_name\"]\n",
    "del df[\"round\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c945a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Unique Player IDs\n",
    "df['player_id'] = df['name'].astype('category').cat.codes\n",
    "\n",
    "# Convert Kickoff Time to datetime and Extract Features\n",
    "df['kickoff_time'] = pd.to_datetime(df['kickoff_time'])\n",
    "df['year'] = df['kickoff_time'].dt.year\n",
    "df['month'] = df['kickoff_time'].dt.month\n",
    "df['day_of_month'] = df['kickoff_time'].dt.day\n",
    "df['day_of_week'] = df['kickoff_time'].dt.dayofweek\n",
    "df['time'] = df['kickoff_time'].dt.hour * 100 + df['kickoff_time'].dt.minute\n",
    "\n",
    "# Convert 'was_home' from boolean to int64\n",
    "df['was_home'] = df['was_home'].astype(int)\n",
    "\n",
    "# Convert positions to numbers\n",
    "position_mapping = {'GK': 0, 'DEF': 1, 'MID': 2, 'FWD': 3}\n",
    "df['position'] = df['position'].map(position_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba52b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping player_id to team_x\n",
    "player_team_mapping = df[df['team_x'].notna()][['player_id', 'team_x']].set_index('player_id')['team_x'].to_dict()\n",
    "\n",
    "# Fill in NaN values in 'team_x' based on player_id mapping\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['team_x']):\n",
    "        player_id = row['player_id']\n",
    "        if player_id in player_team_mapping:\n",
    "            df.at[index, 'team_x'] = player_team_mapping[player_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ade459fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team: Arsenal, Code: 1\n",
      "Team: Aston Villa, Code: 2\n",
      "Team: Bournemouth, Code: 3\n",
      "Team: Brentford, Code: 4\n",
      "Team: Brighton, Code: 5\n",
      "Team: Burnley, Code: 6\n",
      "Team: Chelsea, Code: 7\n",
      "Team: Crystal Palace, Code: 8\n",
      "Team: Everton, Code: 9\n",
      "Team: Fulham, Code: 10\n",
      "Team: Leeds, Code: 11\n",
      "Team: Leicester, Code: 12\n",
      "Team: Liverpool, Code: 13\n",
      "Team: Luton, Code: 14\n",
      "Team: Man City, Code: 15\n",
      "Team: Man Utd, Code: 16\n",
      "Team: Newcastle, Code: 17\n",
      "Team: Norwich, Code: 18\n",
      "Team: Nott'm Forest, Code: 19\n",
      "Team: Sheffield Utd, Code: 20\n",
      "Team: Southampton, Code: 21\n",
      "Team: Spurs, Code: 22\n",
      "Team: Watford, Code: 23\n",
      "Team: West Brom, Code: 24\n",
      "Team: West Ham, Code: 25\n",
      "Team: Wolves, Code: 26\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map teams to codes\n",
    "team_codes = {}\n",
    "teams = df['team_x'].dropna().unique()\n",
    "teams.sort()  # Sort teams alphabetically\n",
    "\n",
    "# Assign codes to teams\n",
    "for i, team in enumerate(teams):\n",
    "    team_codes[team] = i + 1  # Start codes from 1\n",
    "\n",
    "# Create a new column 'team_code' in the DataFrame\n",
    "df['team_code'] = df['team_x'].map(team_codes)\n",
    "\n",
    "# Display team names and their codes\n",
    "for team, code in team_codes.items():\n",
    "    print(f\"Team: {team}, Code: {code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a899c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'new_value' and initialize it with the 'value' column\n",
    "df['new_value'] = df['value']\n",
    "\n",
    "# Create a dictionary to store the manually input 'new_value' for each player name\n",
    "player_new_value_dict = {\n",
    "    'Erling Haaland': 140,\n",
    "    'Harry Kane': 125,\n",
    "    'Mohamed Salah': 125,\n",
    "    'Kevin De Bruyne': 105,\n",
    "    'Marcus Rashford': 90,\n",
    "    'Son Heung-min': 90,\n",
    "    'Heung-Min Son': 90,\n",
    "    'Bruno Miguel Borges Fernandes': 85,\n",
    "    'Bukayo Saka': 85,\n",
    "    'Martin Ødegaard': 85,\n",
    "    'Trent Alexander-Arnold': 80,\n",
    "    'Diogo Jota': 80,\n",
    "    'Gabriel Martinelli': 80,\n",
    "    'Ollie Watkins': 80,\n",
    "    'Callum Wilson': 80,\n",
    "    'Darwin Nuñez': 75,\n",
    "    'Phil Foden': 75,\n",
    "    'Jack Grealish': 75,\n",
    "    'Kai Havertz': 75,\n",
    "    'Luis Diaz': 75,\n",
    "    'James Maddison': 75,\n",
    "    'Aleksandar Mitrović': 75,\n",
    "    'Jarrod Bowen': 70,\n",
    "    'Dejan Kulusevski': 70,\n",
    "    'Mason Mount': 70,\n",
    "    'Richarlison': 70,\n",
    "    'Jadon Sancho': 70,\n",
    "    'Raheem Sterling': 70,\n",
    "    'Leandro Trossard': 70,\n",
    "    'Miguel Almirón Rejala': 65,\n",
    "    'Harvey Barnes': 65,\n",
    "    'Bernardo Veiga de Carvalho e Silva': 65,\n",
    "    'Moussa Diaby': 65,\n",
    "    'Eberechi Eze': 65,\n",
    "    'Pascal Gross': 65,\n",
    "    'Julian Alvarez': 65,\n",
    "    'Solly March': 65,\n",
    "    'Kaoru Mitoma': 65,\n",
    "    'Kieran Trippier': 65,\n",
    "    'Joao Cancelo': 60,\n",
    "    'Danny Ings': 60,\n",
    "    'Lucas Paqueta': 60,\n",
    "    'Alexis Mac Allister': 60,\n",
    "    'Virgil Van Dijk': 60,\n",
    "    'Yoane Wissa': 60,\n",
    "    'Reece James': 55,\n",
    "    'Benjamin Chilwell': 55,\n",
    "    'Alisson Ramses Becker': 55,\n",
    "    'Ederson Santana de Moraes': 55,\n",
    "    'Nick Pope': 55,\n",
    "    'Eddie Nketiah': 55,\n",
    "    'Ruben Gato Alves Dias': 55,\n",
    "    'John Stones': 55,\n",
    "    'Luke Shaw': 55,\n",
    "    'Aaron Ramsdale': 50,\n",
    "    'Pervis Estupiñan': 50,\n",
    "    'William Saliba': 50,\n",
    "    'Fabian Schär': 50,\n",
    "    'Gabriel dos Santos Magalhães': 50,\n",
    "    'Robert Sanchez': 45,\n",
    "    'Jordan Pickford': 45,\n",
    "    'Sven Botman': 45,\n",
    "    'Tyrone Mings': 45\n",
    "}\n",
    "\n",
    "# Update the 'new_value' column with the manually input 'new_value' for each player name\n",
    "for player_name, new_value in player_new_value_dict.items():\n",
    "    df.loc[df['name'] == player_name, 'new_value'] = new_value\n",
    "\n",
    "# Define a dictionary to map player names to their new teams\n",
    "player_team_changes = {\n",
    "    'Mason Mount': 'Man Utd',\n",
    "    'James Maddison': 'Spurs',\n",
    "    'Declan Rice': 'Arsenal',\n",
    "    'Kai Havertz': 'Arsenal',\n",
    "    'Youri Tielemans': 'Aston Villa',\n",
    "    'João Pedro Junqueira de Jesus': 'Brighton',\n",
    "    'Robert Sánchez': 'Chelsea',\n",
    "    'Ashley Young': 'Everton',\n",
    "    'Alexis Mac Allister': 'Liverpool',\n",
    "    'Harvey Barnes': 'Newcastle'\n",
    "}\n",
    "\n",
    "# Update the 'team_x' column for the players\n",
    "for player_name, new_team in player_team_changes.items():\n",
    "    df.loc[df['name'] == player_name, 'team_x'] = new_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5d5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Prepare Data\n",
    "X = df.drop(['name', 'kickoff_time', 'team_x','total_points'], axis=1)\n",
    "y = df['total_points']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c9ac3e-f0b9-4409-a234-2cba90dcb3e8",
   "metadata": {},
   "source": [
    "### Creating ML model and comparing several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8a3a246",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2023-24'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2734803/3927091007.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Linear Regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Make predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlr_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    610\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         raise ValueError(\n\u001b[1;32m   1298\u001b[0m             \u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m requires y to be passed, but the target y is None\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2023-24'"
     ]
    }
   ],
   "source": [
    "# Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "lr_y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "lr_mse = mean_squared_error(y_test, lr_y_pred)\n",
    "print(\"Linear Regression Mean Squared Error (MSE):\", lr_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba5a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting model\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "print(\"Gradient Boosting Mean Squared Error (MSE):\", gb_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbde37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram-based Gradient Boosting model\n",
    "hgb_model = HistGradientBoostingRegressor()\n",
    "\n",
    "# Train the model\n",
    "hgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "hgb_y_pred = hgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "hgb_mse = mean_squared_error(y_test, hgb_y_pred)\n",
    "print(\"Histogram-based Gradient Boosting Mean Squared Error (MSE):\", gb_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e25228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "print(\"Random Forest Mean Squared Error (MSE):\", rf_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de9f72-ee39-4117-9901-6733310585d6",
   "metadata": {},
   "source": [
    "### Calculating Weighted Predicted Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69abf6b1-8809-4b7c-b807-0356b9dbe850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict total_points for all players\n",
    "df['predicted_total_points'] = rf_model.predict(X)\n",
    "\n",
    "# Convert position to string\n",
    "df['position'] = df['position'].astype(str)\n",
    "\n",
    "# Convert kickoff_time to timezone-naive datetime\n",
    "df['kickoff_time'] = pd.to_datetime(df['kickoff_time']).dt.tz_localize(None)\n",
    "\n",
    "# Calculate days ago for each match\n",
    "df['days_ago'] = (pd.Timestamp('now') - df['kickoff_time']).dt.days\n",
    "\n",
    "# Define the decay rate for exponential weighting\n",
    "decay_rate = 0.001\n",
    "\n",
    "# Calculate weights based on match dates\n",
    "df['weight'] = np.exp(-decay_rate * df['days_ago'])\n",
    "\n",
    "# Fixture difficulty ratings dictionary\n",
    "fixture_difficulty = {\n",
    "    'Arsenal': [1.86, 1.08, 1.65, 1.42, 1.23],\n",
    "    'Aston Villa': [0.84, 1.73, 1.25, 0.83, 1.57],\n",
    "    'Bournemouth': [1.60, 0.83, 1.56, 0.99, 1.50],\n",
    "    'Brentford': [1.56, 1.16, 1.57, 1.81, 0.84],\n",
    "    'Brighton': [1.87, 1.34, 1.60, 1.30, 0.93],\n",
    "    'Burnley': [0.97, 0, 1.42, 1.56, 1.36],\n",
    "    'Chelsea': [1.29, 1.11, 1.87, 1.86, 1.31],\n",
    "    'Crystal Palace': [1.40, 1.29, 0.99, 1.83, 0.95],\n",
    "    'Everton': [1.65, 0.95, 1.83, 1.40, 1.29],\n",
    "    'Fulham': [1.23, 1.47, 0.83, 0.58, 1.87],\n",
    "    'Liverpool': [1.02, 1.81, 0.84, 1.42, 1.34],\n",
    "    'Man City': [1.25, 1.30, 1.40, 1.65, 1.11],\n",
    "    'Man Utd': [1.83, 1.06, 1.86, 0.83, 1.37],\n",
    "    'Newcastle': [1.42, 0.58, 1.29, 0.89, 1.47],\n",
    "    'Nott’m Forest': [0.83, 1.89, 0.93, 1.02, 1.75],\n",
    "    'Sheffield Utd': [1.57, 1.36, 0.97, 1.73, 1.06],\n",
    "    'Spurs': [0.99, 1.42, 1.31, 1.25, 1.89],\n",
    "    'West Ham': [1.31, 1.50, 0.89, 1.39, 0.97],\n",
    "    'Wolves': [0.93, 1.37, 1.23, 1.08, 1.29]\n",
    "}\n",
    "\n",
    "# Define fixture weights and match weights in the ratio of 24, 22, 20, 18, 16\n",
    "fixture_weights = {\n",
    "    'Arsenal': [1.4664], 'Aston Villa': [1.2328], 'Bournemouth': [1.2968], 'Brentford': [1.4038],\n",
    "    'Brighton': [1.4464], 'Burnley': [1.0156], 'Chelsea': [1.4722], 'Crystal Palace': [1.2992],\n",
    "    'Everton': [1.4294], 'Fulham': [1.1882], 'Liverpool': [1.281], 'Man City': [1.3406],\n",
    "    'Man Utd': [1.413], 'Newcastle': [1.1218], 'Nott’m Forest': [1.2646], 'Sheffield Utd': [1.351],\n",
    "    'Spurs': [1.3394], 'West Ham': [1.2278], 'Wolves': [1.1714]\n",
    "}\n",
    "\n",
    "# Create a new column 'weighted_predicted_points'\n",
    "df['weighted_predicted_points'] = df.apply(\n",
    "    lambda row: row['predicted_total_points'] * row['weight'] * fixture_weights.get(row['team_x'], [0])[0],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create a list of players to be excluded from the team\n",
    "players_to_exclude = [\n",
    "    # 'Tim Krul', 'Michail Antonio', 'Matheus Pereira', 'Gabriel Fernando de Jesus', 'Roberto Firmino', 'Sergio Romero', 'Marcos Alonso', 'Cédric Soares',\n",
    "    #                  'Lucas Rodrigues Moura da Silva', 'Fraser Forster', 'Anthony Martial', 'Chris Wood', 'Gareth Bale', 'Bruno Guimarães Rodriguez Moura', 'Son Heung-min',\n",
    "    #                  'Jack Harrison', 'Ayoze Pérez', 'Kurt Zouma', 'João Cancelo','Pablo Fornals', 'Christian Pulisic', 'Reiss Nelson', 'Kevin De Bruyne', 'Richarlison de Andrade',\n",
    "    #                   'Kasper Schmeichel', 'Eldin Jakupovic', 'Tom Heaton', 'Matt Doherty', 'Kyle Walker-Peters', 'Sergio Agüero', 'Romelu Lukaku', 'Riyad Mahrez', 'Leandro Trossard',\n",
    "    #                  'Dean Henderson', 'Marcus Tavernier', 'Ivan Toney', 'Kelechi Iheanacho', 'Kieffer Moore', 'Adam Lallana', 'João Pedro Cavaco Cancelo', 'Benjamin Mendy',\n",
    "    #                  'Edinson Cavani', 'Sadio Mané', 'Cristiano Ronaldo dos Santos Aveiro', 'Timo Werner', 'Pierre-Emerick Aubameyang', 'Tammy Abraham', 'Kieran Tierney',\n",
    "    #                  'Dominic Calvert-Lewin', 'Raphaël Varane', 'Christian Eriksen', 'Darwin Núñez Ribeiro', 'Edward Nketiah', 'Danny Ings', 'Pontus Jansson', 'Oleksandr Zinchenko'\n",
    "                     ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a6c93-5fe5-4da4-93c4-529cf8663498",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixture_weights_df = pd.DataFrame.from_dict(fixture_weights, orient='index', columns=['Fixture_Weight'])\n",
    "fixture_weights_df = fixture_weights_df.sort_values(by='Fixture_Weight', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "fixture_weights_df['Fixture_Weight'].plot(kind='bar')\n",
    "plt.title('Fixture Weights by Team')\n",
    "plt.xlabel('Team')\n",
    "plt.ylabel('Fixture Weight')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4af9e8-8e4c-40d3-b4ad-af04013e6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out excluded players\n",
    "filtered_df = df[~df['name'].isin(players_to_exclude)]\n",
    "\n",
    "# Create a dictionary to map positions to their index\n",
    "position_indices = {'0.0': 0, '1.0': 1, '2.0': 2, '3.0': 3}\n",
    "position_labels = {'0.0': 'GK', '1.0': 'DEF', '2.0': 'MID', '3.0': 'FWD'}\n",
    "\n",
    "# Initialize a figure with subplots for each position\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "fig.suptitle('Top Players by Position with Highest Weighted Predicted Points', fontsize=16)\n",
    "\n",
    "# Loop through each position and create a subplot\n",
    "for position, ax in zip(position_indices.keys(), axes.flat):\n",
    "    # Filter players by position\n",
    "    position_players = filtered_df[filtered_df['position'] == position]\n",
    "    \n",
    "    # Sort players by 'weighted_predicted_points' in descending order\n",
    "    position_players_sorted = position_players.sort_values(by='weighted_predicted_points', ascending=False)\n",
    "    \n",
    "    # Select the top 10 players\n",
    "    top_position_players = position_players_sorted.head(10)\n",
    "    \n",
    "    # Create a bar plot for the position\n",
    "    ax.barh(top_position_players['name'], top_position_players['weighted_predicted_points'])\n",
    "    ax.set_title(f'Position {position_labels[position]}')\n",
    "    ax.set_xlabel('Weighted Predicted Points')\n",
    "    ax.set_ylabel('Player')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba71bb-97a6-4c64-b99a-8040d8e1085c",
   "metadata": {},
   "source": [
    "### Creating the Optimization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbfd32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PuLP optimization problem\n",
    "model = LpProblem(name=\"FPL_Team_Selection\", sense=LpMaximize)\n",
    "\n",
    "# Variables: Binary variable indicating whether a player is selected or not\n",
    "players = df.index\n",
    "player_vars = LpVariable.dicts(\"Player\", players, cat=\"Binary\")\n",
    "played_2023_vars = LpVariable.dicts(\"Played_2023\", players, cat=\"Binary\")\n",
    "\n",
    "# Filter out players from teams not in the fixture difficulty dictionary\n",
    "players = [i for i in players if df['team_x'][i] in fixture_difficulty]\n",
    "\n",
    "# Create a mapping of filtered players to their indices\n",
    "filtered_players_indices = {i: idx for idx, i in enumerate(players)}\n",
    "\n",
    "def add_player_constraints(model, players):\n",
    "    # Objective constraint\n",
    "    model += lpSum(df['weighted_predicted_points'][i] for i in players)\n",
    "    \n",
    "    # Total budget constraints\n",
    "    model += lpSum(df['new_value'][i] * player_vars[i] for i in players) <= 830\n",
    "    model += lpSum(df['new_value'][i] * player_vars[i] for i in players) >= 820\n",
    "    \n",
    "    # Position constraints\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '0') == 1\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '1') >= 3\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '1') <= 5\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '2') >= 2\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '2') <= 5\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '3') >= 1\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '3') <= 3\n",
    "    \n",
    "    # A player must have played in 2023 if selected\n",
    "    for i in players:\n",
    "        model += lpSum(player_vars[i] for i in players) <= 1\n",
    "        model += played_2023_vars[i] >= player_vars[i]\n",
    "        model += played_2023_vars[i] <= 1 - (1 - player_vars[i])\n",
    "    \n",
    "    # Exactly 11 players must be selected\n",
    "    model += lpSum(player_vars[i] for i in players) == 11\n",
    "    \n",
    "    # Exclude specific players from the team\n",
    "    for player in players:\n",
    "        if df['name'][player] in players_to_exclude:\n",
    "            model += player_vars[player] == 0\n",
    "            \n",
    "    # No more than 3 players from a single team\n",
    "    selected_players_per_team = {team: [] for team in fixture_difficulty}\n",
    "    for player in players:\n",
    "        team_name = df['team_x'][player]\n",
    "        selected_players_per_team[team_name].append(player)\n",
    "    for team, selected_players in selected_players_per_team.items():\n",
    "        model += lpSum(player_vars[i] for i in selected_players) <= 3\n",
    " \n",
    "# Add all player constraints\n",
    "add_player_constraints(model, players)\n",
    "\n",
    "# Solve the optimization problem\n",
    "model.solve()\n",
    "\n",
    "# Get the recommended players\n",
    "recommended_players = [i for i in players if player_vars[i].varValue == 1]\n",
    "\n",
    "# Print the recommended players and their positions\n",
    "for player in recommended_players:\n",
    "    print(f\"Player: {df['name'][player]}, Position: {df['position'][player]}, Predicted Points: {df['weighted_predicted_points'][player]}, Value: {df['new_value'][player]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb8cf8-c068-4a5b-8148-0c5b36c7bcfc",
   "metadata": {},
   "source": [
    "@misc{anand2016fantasypremierleague,\n",
    "  title = {{FPL Historical Dataset}},\n",
    "  author = {Anand, Vaastav},\n",
    "  year = {2022},\n",
    "  howpublished = {Retrieved August 2023 from \\url{https://github.com/vaastav/Fantasy-Premier-League/}}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
