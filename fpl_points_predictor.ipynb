{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efb9b53-ab5e-4cec-b9fa-f2e6f216bf05",
   "metadata": {},
   "source": [
    "### Importing Necessary Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a657b",
   "metadata": {},
   "source": [
    "`pandas` and `numpy` for dataframe processing.\n",
    "\n",
    "`sklearn` as a source of regressor models\n",
    "\n",
    "`pulp` linear problem solvers for team composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "826f8c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from pulp import LpMaximize, LpProblem, LpVariable, lpSum, LpInteger, LpStatus, LpBinary, LpConstraintVar, LpConstraint, LpAffineExpression\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224b450-bbfa-42c2-a0c0-56c8718de675",
   "metadata": {},
   "source": [
    "### Importing the Data\n",
    "\n",
    "FPL has API which can be used to query current and historical data. Luckily, its also being aggregated into a single CSV at https://github.com/vaastav/Fantasy-Premier-League (imported as git submodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2aacdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data/cleaned_merged_seasons.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d64dbb",
   "metadata": {},
   "source": [
    "### Data example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee34b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove string data from the dataset\n",
    "del df[\"season_x\"]\n",
    "del df[\"opp_team_name\"]\n",
    "del df[\"round\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0c945a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Unique Player IDs\n",
    "df['player_id'] = df['name'].astype('category').cat.codes\n",
    "\n",
    "# Convert Kickoff Time to datetime and Extract Features\n",
    "df['kickoff_time'] = pd.to_datetime(df['kickoff_time'])\n",
    "df['year'] = df['kickoff_time'].dt.year\n",
    "df['month'] = df['kickoff_time'].dt.month\n",
    "df['day_of_month'] = df['kickoff_time'].dt.day\n",
    "df['day_of_week'] = df['kickoff_time'].dt.dayofweek\n",
    "df['time'] = df['kickoff_time'].dt.hour * 100 + df['kickoff_time'].dt.minute\n",
    "\n",
    "# Convert 'was_home' from boolean to int64\n",
    "df['was_home'] = df['was_home'].astype(int)\n",
    "\n",
    "# Convert positions to numbers\n",
    "position_mapping = {'GK': 0, 'DEF': 1, 'MID': 2, 'FWD': 3}\n",
    "df['position'] = df['position'].map(position_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ba52b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping player_id to team_x\n",
    "player_team_mapping = df[df['team_x'].notna()][['player_id', 'team_x']].set_index('player_id')['team_x'].to_dict()\n",
    "\n",
    "# Fill in NaN values in 'team_x' based on player_id mapping\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['team_x']):\n",
    "        player_id = row['player_id']\n",
    "        if player_id in player_team_mapping:\n",
    "            df.at[index, 'team_x'] = player_team_mapping[player_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade459fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map teams to codes\n",
    "team_codes = {}\n",
    "teams = df['team_x'].dropna().unique()\n",
    "teams.sort()  # Sort teams alphabetically\n",
    "\n",
    "# Assign codes to teams\n",
    "for i, team in enumerate(teams):\n",
    "    team_codes[team] = i + 1  # Start codes from 1\n",
    "\n",
    "# Create a new column 'team_code' in the DataFrame\n",
    "df['team_code'] = df['team_x'].map(team_codes)\n",
    "\n",
    "# Display team names and their codes\n",
    "for team, code in team_codes.items():\n",
    "    print(f\"Team: {team}, Code: {code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a899c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'new_value' and initialize it with the 'value' column\n",
    "df['new_value'] = df['value']\n",
    "\n",
    "# Create a dictionary to store the manually input 'new_value' for each player name\n",
    "player_new_value_dict = {\n",
    "    'Erling Haaland': 140,\n",
    "    'Harry Kane': 125,\n",
    "    'Mohamed Salah': 125,\n",
    "    'Kevin De Bruyne': 105,\n",
    "    'Marcus Rashford': 90,\n",
    "    'Son Heung-min': 90,\n",
    "    'Heung-Min Son': 90,\n",
    "    'Bruno Miguel Borges Fernandes': 85,\n",
    "    'Bukayo Saka': 85,\n",
    "    'Martin Ødegaard': 85,\n",
    "    'Trent Alexander-Arnold': 80,\n",
    "    'Diogo Jota': 80,\n",
    "    'Gabriel Martinelli': 80,\n",
    "    'Ollie Watkins': 80,\n",
    "    'Callum Wilson': 80,\n",
    "    'Darwin Nuñez': 75,\n",
    "    'Phil Foden': 75,\n",
    "    'Jack Grealish': 75,\n",
    "    'Kai Havertz': 75,\n",
    "    'Luis Diaz': 75,\n",
    "    'James Maddison': 75,\n",
    "    'Aleksandar Mitrović': 75,\n",
    "    'Jarrod Bowen': 70,\n",
    "    'Dejan Kulusevski': 70,\n",
    "    'Mason Mount': 70,\n",
    "    'Richarlison': 70,\n",
    "    'Jadon Sancho': 70,\n",
    "    'Raheem Sterling': 70,\n",
    "    'Leandro Trossard': 70,\n",
    "    'Miguel Almirón Rejala': 65,\n",
    "    'Harvey Barnes': 65,\n",
    "    'Bernardo Veiga de Carvalho e Silva': 65,\n",
    "    'Moussa Diaby': 65,\n",
    "    'Eberechi Eze': 65,\n",
    "    'Pascal Gross': 65,\n",
    "    'Julian Alvarez': 65,\n",
    "    'Solly March': 65,\n",
    "    'Kaoru Mitoma': 65,\n",
    "    'Kieran Trippier': 65,\n",
    "    'Joao Cancelo': 60,\n",
    "    'Danny Ings': 60,\n",
    "    'Lucas Paqueta': 60,\n",
    "    'Alexis Mac Allister': 60,\n",
    "    'Virgil Van Dijk': 60,\n",
    "    'Yoane Wissa': 60,\n",
    "    'Reece James': 55,\n",
    "    'Benjamin Chilwell': 55,\n",
    "    'Alisson Ramses Becker': 55,\n",
    "    'Ederson Santana de Moraes': 55,\n",
    "    'Nick Pope': 55,\n",
    "    'Eddie Nketiah': 55,\n",
    "    'Ruben Gato Alves Dias': 55,\n",
    "    'John Stones': 55,\n",
    "    'Luke Shaw': 55,\n",
    "    'Aaron Ramsdale': 50,\n",
    "    'Pervis Estupiñan': 50,\n",
    "    'William Saliba': 50,\n",
    "    'Fabian Schär': 50,\n",
    "    'Gabriel dos Santos Magalhães': 50,\n",
    "    'Robert Sanchez': 45,\n",
    "    'Jordan Pickford': 45,\n",
    "    'Sven Botman': 45,\n",
    "    'Tyrone Mings': 45\n",
    "}\n",
    "\n",
    "# Update the 'new_value' column with the manually input 'new_value' for each player name\n",
    "for player_name, new_value in player_new_value_dict.items():\n",
    "    df.loc[df['name'] == player_name, 'new_value'] = new_value\n",
    "\n",
    "# Define a dictionary to map player names to their new teams\n",
    "player_team_changes = {\n",
    "    'Mason Mount': 'Man Utd',\n",
    "    'James Maddison': 'Spurs',\n",
    "    'Declan Rice': 'Arsenal',\n",
    "    'Kai Havertz': 'Arsenal',\n",
    "    'Youri Tielemans': 'Aston Villa',\n",
    "    'João Pedro Junqueira de Jesus': 'Brighton',\n",
    "    'Robert Sánchez': 'Chelsea',\n",
    "    'Ashley Young': 'Everton',\n",
    "    'Alexis Mac Allister': 'Liverpool',\n",
    "    'Harvey Barnes': 'Newcastle'\n",
    "}\n",
    "\n",
    "# Update the 'team_x' column for the players\n",
    "for player_name, new_team in player_team_changes.items():\n",
    "    df.loc[df['name'] == player_name, 'team_x'] = new_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4d5d5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Prepare Data\n",
    "X = df.drop(['name', 'kickoff_time', 'team_x','total_points'], axis=1)\n",
    "y = df['total_points']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c9ac3e-f0b9-4409-a234-2cba90dcb3e8",
   "metadata": {},
   "source": [
    "### Creating ML model and comparing several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cdfc60d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_timings = pd.DataFrame(columns=['Model', 'Duration', 'MSE'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af998597",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a3a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Linear Regression Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "stop_time = time.time()\n",
    "model_timings.loc[len(model_timings.index)] = [\n",
    "  'LinearRegression', stop_time - start_time, mse\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba5a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Gradient Boosting model\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Gradient Boosting Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "stop_time = time.time()\n",
    "model_timings.loc[len(model_timings.index)] = [\n",
    "  'GradientBoostingRegressor', stop_time - start_time, mse\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbde37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Histogram-based Gradient Boosting model\n",
    "model = HistGradientBoostingRegressor()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Histogram-based Gradient Boosting Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "stop_time = time.time()\n",
    "model_timings.loc[len(model_timings.index)] = [\n",
    "  'HistGradientBoostingRegressor', stop_time - start_time, mse\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc3746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Histogram-based Gradient Boosting model\n",
    "model = HistGradientBoostingRegressor(max_iter=10000)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Histogram-based Gradient Boosting (max_iter=10000) Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "stop_time = time.time()\n",
    "model_timings.loc[len(model_timings.index)] = [\n",
    "  'HistGradientBoostingRegressor (max_iter=10000)', stop_time - start_time, mse\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d519b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Histogram-based Gradient Boosting model\n",
    "winner_model = HistGradientBoostingRegressor(min_samples_leaf=5, max_iter=10000)\n",
    "\n",
    "# Train the model\n",
    "winner_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = winner_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Histogram-based Gradient Boosting (min_samples_leaf=5, max_iter=10000) Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "stop_time = time.time()\n",
    "model_timings.loc[len(model_timings.index)] = [\n",
    "  'HistGradientBoostingRegressor (min_samples_leaf=5, max_iter=10000)', stop_time - start_time, mse\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Histogram-based Gradient Boosting model\n",
    "winner_model = HistGradientBoostingRegressor(min_samples_leaf=5, max_iter=10000, validation_fraction=0.1, n_iter_no_change=10)\n",
    "\n",
    "# Train the model\n",
    "winner_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = winner_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Histogram-based Gradient Boosting (early stopping) Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "stop_time = time.time()\n",
    "model_timings.loc[len(model_timings.index)] = [\n",
    "  'HistGradientBoostingRegressor (early stopping)', stop_time - start_time, mse\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e25228",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Random Forest Regression model\n",
    "rg_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Random Forest Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "stop_time = time.time()\n",
    "model_timings.loc[len(model_timings.index)] = [\n",
    "  'RandomForestRegressor', stop_time - start_time, mse\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "10b3bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# # Random Forest Regression model - n_estimators\n",
    "# model = RandomForestRegressor(n_estimators=1000)\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model using MSE\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Random Forest (n_estimators=1000) Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# stop_time = time.time()\n",
    "# model_timings.loc[len(model_timings.index)] = [\n",
    "#   'RandomForestRegressor n_estimators=1000', stop_time - start_time, mse\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "21aed834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# # Random Forest Regression model - friedman_mse criterion\n",
    "# model = RandomForestRegressor(criterion='friedman_mse')\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model using MSE\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Random Forest (criterion=friedman_mse) Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# stop_time = time.time()\n",
    "# model_timings.loc[len(model_timings.index)] = [\n",
    "#   'RandomForestRegressor criterion=friedman_mse', stop_time - start_time, mse\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "77aff8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# # Random Forest Regression model - max_features=5\n",
    "# model = RandomForestRegressor(max_features=5)\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model using MSE\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Random Forest (max_features=5) Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# stop_time = time.time()\n",
    "# model_timings.loc[len(model_timings.index)] = [\n",
    "#   'RandomForestRegressor max_features=5', stop_time - start_time, mse\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c3150fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# # Random Forest Regression model - oob_score=True\n",
    "# model = RandomForestRegressor(oob_score=True)\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Evaluate the model using MSE\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"Random Forest (oob_score=True) Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# stop_time = time.time()\n",
    "# model_timings.loc[len(model_timings.index)] = [\n",
    "#   'RandomForestRegressor oob_score=True', stop_time - start_time, mse\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9533607",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_timings.sort_values(by='MSE', ascending=True, inplace=True)\n",
    "fig = model_timings.plot.bar(x='MSE', y='Model', log_x=True, title=\"Mean Square Error for each model\", orientation='h')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc08e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_timings.sort_values(by='Duration', ascending=True, inplace=True)\n",
    "fig = model_timings.plot.bar(x='Duration', y='Model', log_x=True, title=\"Training time for each model\", orientation='h')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de9f72-ee39-4117-9901-6733310585d6",
   "metadata": {},
   "source": [
    "### Calculating Weighted Predicted Points\n",
    "\n",
    "Players are not getting any younger, the points they would have scored last year are no longer important.\n",
    "This makes the model to biased toward recent matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "69abf6b1-8809-4b7c-b807-0356b9dbe850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict total_points for all players\n",
    "df['predicted_total_points'] = winner_model.predict(X)\n",
    "\n",
    "# Convert position to string\n",
    "df['position'] = df['position'].astype(str)\n",
    "\n",
    "# Convert kickoff_time to timezone-naive datetime\n",
    "df['kickoff_time'] = pd.to_datetime(df['kickoff_time']).dt.tz_localize(None)\n",
    "\n",
    "# Calculate days ago for each match\n",
    "df['days_ago'] = (pd.Timestamp('now') - df['kickoff_time']).dt.days\n",
    "\n",
    "# Define the decay rate for exponential weighting\n",
    "decay_rate = 0.001\n",
    "\n",
    "# Calculate weights based on match dates\n",
    "df['weight'] = np.exp(-decay_rate * df['days_ago'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86887c7",
   "metadata": {},
   "source": [
    "### Match weight\n",
    "\n",
    "Some matches are more complicated than the others, the model should be biased toward the matches with leaders of the league"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8fed154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixture difficulty ratings dictionary\n",
    "fixture_difficulty = {\n",
    "    'Arsenal': [1.86, 1.08, 1.65, 1.42, 1.23],\n",
    "    'Aston Villa': [0.84, 1.73, 1.25, 0.83, 1.57],\n",
    "    'Bournemouth': [1.60, 0.83, 1.56, 0.99, 1.50],\n",
    "    'Brentford': [1.56, 1.16, 1.57, 1.81, 0.84],\n",
    "    'Brighton': [1.87, 1.34, 1.60, 1.30, 0.93],\n",
    "    'Burnley': [0.97, 0, 1.42, 1.56, 1.36],\n",
    "    'Chelsea': [1.29, 1.11, 1.87, 1.86, 1.31],\n",
    "    'Crystal Palace': [1.40, 1.29, 0.99, 1.83, 0.95],\n",
    "    'Everton': [1.65, 0.95, 1.83, 1.40, 1.29],\n",
    "    'Fulham': [1.23, 1.47, 0.83, 0.58, 1.87],\n",
    "    'Liverpool': [1.02, 1.81, 0.84, 1.42, 1.34],\n",
    "    'Man City': [1.25, 1.30, 1.40, 1.65, 1.11],\n",
    "    'Man Utd': [1.83, 1.06, 1.86, 0.83, 1.37],\n",
    "    'Newcastle': [1.42, 0.58, 1.29, 0.89, 1.47],\n",
    "    'Nott’m Forest': [0.83, 1.89, 0.93, 1.02, 1.75],\n",
    "    'Sheffield Utd': [1.57, 1.36, 0.97, 1.73, 1.06],\n",
    "    'Spurs': [0.99, 1.42, 1.31, 1.25, 1.89],\n",
    "    'West Ham': [1.31, 1.50, 0.89, 1.39, 0.97],\n",
    "    'Wolves': [0.93, 1.37, 1.23, 1.08, 1.29]\n",
    "}\n",
    "\n",
    "# Define fixture weights and match weights in the ratio of 24, 22, 20, 18, 16\n",
    "fixture_weights = {\n",
    "    'Arsenal': [1.4664], 'Aston Villa': [1.2328], 'Bournemouth': [1.2968], 'Brentford': [1.4038],\n",
    "    'Brighton': [1.4464], 'Burnley': [1.0156], 'Chelsea': [1.4722], 'Crystal Palace': [1.2992],\n",
    "    'Everton': [1.4294], 'Fulham': [1.1882], 'Liverpool': [1.281], 'Man City': [1.3406],\n",
    "    'Man Utd': [1.413], 'Newcastle': [1.1218], 'Nott’m Forest': [1.2646], 'Sheffield Utd': [1.351],\n",
    "    'Spurs': [1.3394], 'West Ham': [1.2278], 'Wolves': [1.1714]\n",
    "}\n",
    "\n",
    "# Create a new column 'weighted_predicted_points'\n",
    "df['weighted_predicted_points'] = df.apply(\n",
    "    lambda row: row['predicted_total_points'] * row['weight'] * fixture_weights.get(row['team_x'], [0])[0],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb915665",
   "metadata": {},
   "source": [
    "### Remove duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d8d35853",
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_df=df.sort_values(['predicted_total_points']).drop_duplicates(['name'],keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30790d31",
   "metadata": {},
   "source": [
    "### Show most performing players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4af9e8-8e4c-40d3-b4ad-af04013e6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map positions to their index\n",
    "position_indices = {'0.0': 0, '1.0': 1, '2.0': 2, '3.0': 3}\n",
    "position_labels = {'0.0': 'GK', '1.0': 'DEF', '2.0': 'MID', '3.0': 'FWD'}\n",
    "\n",
    "subplot_titles = []\n",
    "for position in position_indices.keys():\n",
    "    subplot_titles += [position_labels[position]]\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=4, cols=1, shared_xaxes=True, subplot_titles=subplot_titles)\n",
    "fig.update_layout(title_text='Top Players by Position with Highest Weighted Predicted Points')\n",
    "\n",
    "# Loop through each position and create a subplot\n",
    "row = 1\n",
    "for position in position_indices.keys():\n",
    "    # Filter players by position\n",
    "    position_players = dedup_df[dedup_df['position'] == position]\n",
    "    \n",
    "    # Sort players by 'weighted_predicted_points' in descending order\n",
    "    position_players_sorted = position_players.sort_values(by='weighted_predicted_points', ascending=False)\n",
    "    \n",
    "    # Select the top 10 players\n",
    "    top_position_players = position_players_sorted.head(10)\n",
    "    \n",
    "    # Create a bar plot for the position\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=top_position_players['weighted_predicted_points'],\n",
    "            y=top_position_players['name'],\n",
    "            orientation='h',\n",
    "        ),\n",
    "        row=row, col=1\n",
    "    )\n",
    "    row += 1\n",
    "\n",
    "fig.update_layout(height=1200, width=800)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dae872",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Which data columns affect the predicted points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rg_model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=[\n",
    "  \"\", \"Permutation Importance (test set)\"\n",
    "])\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "            y=np.array(X_train.columns)[sorted_idx],\n",
    "            x=feature_importance[sorted_idx],\n",
    "            orientation='h'))\n",
    "fig.update_layout(height=1200, width=1200, title=\"Feature Importance (MDI)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba71bb-97a6-4c64-b99a-8040d8e1085c",
   "metadata": {},
   "source": [
    "### Creating the Optimization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbfd32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PuLP optimization problem\n",
    "model = LpProblem(name=\"FPL_Team_Selection\", sense=LpMaximize)\n",
    "\n",
    "# Variables: Binary variable indicating whether a player is selected or not\n",
    "players = df.index\n",
    "player_vars = LpVariable.dicts(\"Player\", players, cat=\"Binary\")\n",
    "played_2023_vars = LpVariable.dicts(\"Played_2023\", players, cat=\"Binary\")\n",
    "\n",
    "# Filter out players from teams not in the fixture difficulty dictionary\n",
    "players = [i for i in players if df['team_x'][i] in fixture_difficulty]\n",
    "\n",
    "# Create a mapping of filtered players to their indices\n",
    "filtered_players_indices = {i: idx for idx, i in enumerate(players)}\n",
    "\n",
    "def add_player_constraints(model, players):\n",
    "    # Objective constraint\n",
    "    model += lpSum(df['weighted_predicted_points'][i] for i in players)\n",
    "    \n",
    "    # Total budget constraints\n",
    "    model += lpSum(df['new_value'][i] * player_vars[i] for i in players) <= 830\n",
    "    model += lpSum(df['new_value'][i] * player_vars[i] for i in players) >= 820\n",
    "    \n",
    "    # Position constraints\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '0.0') == 1\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '1.1') >= 3\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '1.1') <= 5\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '2.0') >= 2\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '2.0') <= 5\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '3.0') >= 1\n",
    "    model += lpSum(player_vars[i] for i in players if df['position'][i] == '3.0') <= 3\n",
    "    \n",
    "    # A player must have played in 2023 if selected\n",
    "    for i in players:\n",
    "        model += lpSum(player_vars[i] for i in players) <= 1\n",
    "        model += played_2023_vars[i] >= player_vars[i]\n",
    "        model += played_2023_vars[i] <= 1 - (1 - player_vars[i])\n",
    "    \n",
    "    # Exactly 11 players must be selected\n",
    "    model += lpSum(player_vars[i] for i in players) == 11\n",
    "               \n",
    "    # No more than 3 players from a single team\n",
    "    selected_players_per_team = {team: [] for team in fixture_difficulty}\n",
    "    for player in players:\n",
    "        team_name = df['team_x'][player]\n",
    "        selected_players_per_team[team_name].append(player)\n",
    "    for team, selected_players in selected_players_per_team.items():\n",
    "        model += lpSum(player_vars[i] for i in selected_players) <= 3\n",
    " \n",
    "# Add all player constraints\n",
    "add_player_constraints(model, players)\n",
    "\n",
    "# Solve the optimization problem\n",
    "model.solve()\n",
    "\n",
    "# Get the recommended players\n",
    "recommended_players = [i for i in players if player_vars[i].varValue == 1]\n",
    "\n",
    "# Print the recommended players and their positions\n",
    "for player in recommended_players:\n",
    "    print(f\"Player: {df['name'][player]}, Position: {position_labels[df['position'][player]]}, Predicted Points: {df['weighted_predicted_points'][player]}, Value: {df['new_value'][player]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb8cf8-c068-4a5b-8148-0c5b36c7bcfc",
   "metadata": {},
   "source": [
    "@misc{anand2016fantasypremierleague,\n",
    "  title = {{FPL Historical Dataset}},\n",
    "  author = {Anand, Vaastav},\n",
    "  year = {2022},\n",
    "  howpublished = {Retrieved August 2023 from \\url{https://github.com/vaastav/Fantasy-Premier-League/}}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
